{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from nalu import NALU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('text.txt', 'r').read()\n",
    "chars = list(set(data)) #set = get unique values\n",
    "VOCAB_SIZE = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars:\n",
      "['9', 'i', 'e', 'Å', 'Q', 'Ã', 'H', '–', '1', ':', 'B', 'h', '»', 'ª', 'r', 'J', 'A', '”', 'q', '—', 'R', '\\xad', '…', '‘', 'N', 'n', '2', 'S', 'I', 'L', '²', 's', '4', 'Y', 'T', 'X', 'Z', 'o', '¶', '0', '•', '\"', '=', 'w', \"'\", ' ', '¡', 'v', 'x', 'U', '7', '*', 'E', 'W', ';', '.', '5', '$', 'b', '¢', 'g', 'K', 'k', '6', '«', 'p', '“', '£', '3', 'P', 'm', '´', 'Â', 'c', 'd', 'j', 'D', 'O', '¨', '8', '’', '¿', 'G', ',', 't', 'C', 'ï', '\\n', 'a', 'V', '€', 'u', 'z', '®', 'M', 'º', 'l', 'f', 'F', '?', 'y']\n",
      "\n",
      "VOCAB_SIZE: 101\n"
     ]
    }
   ],
   "source": [
    "print('chars:\\n{}\\n\\nVOCAB_SIZE: {}'.format(chars, VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {i:char for i, char in enumerate(chars)}\n",
    "char_to_idx = {char:i for i, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 60 #input sequence length\n",
    "N_FEATURES = VOCAB_SIZE  # For 1 hot encoding\n",
    "N_SEQ = int(np.floor((len(data) - 1)/SEQ_LENGTH))\n",
    "\n",
    "X = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
    "y = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
    "\n",
    "for i in range(N_SEQ):\n",
    "    x_sequence = data[i * SEQ_LENGTH: (i+1) * SEQ_LENGTH]\n",
    "    x_sequence_ix = [char_to_idx[c] for c in x_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][x_sequence_ix[j]] = 1. # One hot encoding\n",
    "    X[i] = input_sequence\n",
    "    \n",
    "    y_sequence = data[i * SEQ_LENGTH + 1: (i + 1) * SEQ_LENGTH + 1] # shifted 1 to the right\n",
    "    y_sequence_ix = [char_to_idx[c] for c in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1. #again, one hot encoding\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4063, 60, 100)\n",
      "(4063, 60, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsloetto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from  keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Activation, CuDNNLSTM\n",
    "\n",
    "# try CuDNNLSTM on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 700 \n",
    "LAYER_NUM = 2\n",
    "NB_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(HIDDEN_DIM,\n",
    "               input_shape=(None, VOCAB_SIZE),\n",
    "               return_sequences = True))\n",
    "\n",
    "for _ in range(LAYER_NUM - 1):\n",
    "    model.add(CuDNNLSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "#model.add(Activation('NULA'))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, None, 700)         2245600   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, None, 700)         3925600   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 100)         70100     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 100)         0         \n",
      "=================================================================\n",
      "Total params: 6,241,300\n",
      "Trainable params: 6,241,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, length):\n",
    "  ix = [np.random.randint(VOCAB_SIZE)]\n",
    "  y_char = [idx_to_char[ix[-1]]]\n",
    "  X = np.zeros((1, length, VOCAB_SIZE))\n",
    "  for i in range(length):\n",
    "    X[0, i, :][ix[-1]] = 1.\n",
    "    ix = np.argmax(model.predict(X[:, :i+1,:])[0], 1)\n",
    "    y_char.append(idx_to_char[ix[-1]])\n",
    "  return ''.join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "# callback to save the model if better\n",
    "filepath=\"tgt_model.hdf5\"\n",
    "save_model_cb = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callback to stop the training if no improvement\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=0)\n",
    "# callback to generate text at epoch end\n",
    "class generateText(Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        print(generate_text(self.model, 100))\n",
    "        \n",
    "generate_text_cb = generateText()\n",
    "\n",
    "callbacks_list = [save_model_cb, early_stopping_cb, generate_text_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, epochs=NB_EPOCHS, callbacks=callbacks_list, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "filepath=\"tgt_model.hdf5\"\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
