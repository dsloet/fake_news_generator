{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from nalu import NALU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('cnn.txt', 'r').read()\n",
    "chars = list(set(data)) #set = get unique values\n",
    "VOCAB_SIZE = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars:\n",
      "['H', '?', 'í', '•', 'q', '.', 'l', \"'\", '6', 'h', 'x', '+', '1', '%', 'é', 'ó', 'L', 'o', 'p', '!', 'ö', 'N', 'y', '$', '’', 'D', ':', '[', 'à', 's', 'ü', 'ï', 'r', 'e', '0', 't', '4', '/', 'K', ')', 'M', '|', 'i', 'J', 'A', 'I', '&', ';', 'u', 'O', '\"', '2', '8', ']', 'd', 'm', 'W', 'B', 'Ç', 'n', '(', 'Z', ' ', 'T', 'ñ', '_', 'C', '5', '“', 'S', 'g', 'P', 'f', 'E', 'V', ',', 'X', 'c', 'j', '–', 'F', 'k', 'z', 'U', '7', '-', 'R', 'Q', 'G', 'v', '”', 'Y', '@', '3', 'w', '—', 'a', '\\n', '9', 'b']\n",
      "\n",
      "VOCAB_SIZE: 100\n"
     ]
    }
   ],
   "source": [
    "print('chars:\\n{}\\n\\nVOCAB_SIZE: {}'.format(chars, VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {i:char for i, char in enumerate(chars)}\n",
    "char_to_idx = {char:i for i, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 60 #input sequence length\n",
    "N_FEATURES = VOCAB_SIZE  # For 1 hot encoding\n",
    "N_SEQ = int(np.floor((len(data) - 1)/SEQ_LENGTH))\n",
    "\n",
    "X_text = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
    "y_text = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
    "\n",
    "for i in range(N_SEQ):\n",
    "    x_sequence = data[i * SEQ_LENGTH: (i+1) * SEQ_LENGTH]\n",
    "    x_sequence_ix = [char_to_idx[c] for c in x_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][x_sequence_ix[j]] = 1. # One hot encoding\n",
    "    X_text[i] = input_sequence\n",
    "    \n",
    "    y_sequence = data[i * SEQ_LENGTH + 1: (i + 1) * SEQ_LENGTH + 1] # shifted 1 to the right\n",
    "    y_sequence_ix = [char_to_idx[c] for c in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1. #again, one hot encoding\n",
    "    y_text[i] = target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063, 60, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063, 60, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n,o = X_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsloetto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from  keras.models import Sequential\n",
    "#from keras.layers import LSTM, TimeDistributed, Dense, Activation, CuDNNLSTM\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "# try CuDNNLSTM on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 7 \n",
    "LAYER_NUM = 2\n",
    "NB_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "keep = 0.5\n",
    "no_of_batches = int(len(X_text)/ BATCH_SIZE)\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.train.exponential_decay(learning_rate = 0.01,\n",
    "                                          global_step = 1,\n",
    "                                          decay_steps = m,\n",
    "                                          decay_rate = 0.95,\n",
    "                                          staircase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, None, o], name = 'input')\n",
    "y_ = tf.placeholder(tf.float32, [None, None, o], name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "w_lstm = tf.Variable(tf.truncated_normal([o, HIDDEN_DIM],\n",
    "                                        mean = 0.0, stddev=1.0,\n",
    "                                        dtype = tf.float32), name = 'w_lstm')\n",
    "b_lstm = tf.Variable(tf.constant(0.1, shape = [HIDDEN_DIM], dtype=tf.float32), name='b_lstm')\n",
    "lstm = tf.nn.rnn_cell.LSTMCell(HIDDEN_DIM, state_is_tuple=True)\n",
    "'''\n",
    "from keras.layers import LSTM\n",
    "lstm = LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE),\n",
    "           return_sequences = True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val, state = tf.nn.dynamic_rnn(lstm, x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val = tf.transpose(val, [1,0,2])\n",
    "#lstm_out = tf.gather(val, int(val.get_shape()[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 1\n",
    "'''\n",
    "num_hidden1 = 700\n",
    "w1 = tf.Variable(tf.truncated_normal([HIDDEN_DIM, num_hidden1],\n",
    "                                        mean = 0.0, stddev=1.0,\n",
    "                                        dtype = tf.float32), name = 'w1')\n",
    "b1 = tf.Variable(tf.constant(0.1, shape = [num_hidden1], dtype=tf.float32), name='b1')\n",
    "h1 = tf.nn.relu6(tf.matmul(lstm_out, w1)+b1, name = 'h1')\n",
    "'''\n",
    "lstm = LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE),\n",
    "           return_sequences = True)(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 2\n",
    "lstm = LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE),\n",
    "           return_sequences = True)(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_output = VOCAB_SIZE\\nw2 = tf.Variable(tf.truncated_normal([num_hidden1, num_output],\\n                                    mean = 0.0, stddev=1.0,\\n                                    dtype = tf.float32))\\nb2 = tf.Variable(tf.constant(0.2, shape=[60, num_output], dtype=tf.float32))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_output = VOCAB_SIZE\n",
    "w2 = tf.Variable(tf.truncated_normal([num_hidden1, num_output],\n",
    "                                    mean = 0.0, stddev=1.0,\n",
    "                                    dtype = tf.float32))\n",
    "b2 = tf.Variable(tf.constant(0.2, shape=[60, num_output], dtype=tf.float32))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "y = tf.nn.relu(tf.matmul(h1, w2)+b2)\n",
    "'''\n",
    "from keras.layers import TimeDistributed, Dense\n",
    "#dense = TimeDistributed(Dense(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Dense(VOCAB_SIZE, activation='relu')(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pred = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax')(h1))\n",
    "#pred = tf.sqrt(tf.reduce_mean(tf.squared_difference(y_, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(y_, y))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 Cost: [[[0.         0.         0.         ... 0.03422884 0.         0.01405166]\n",
      "  [0.         0.         0.         ... 0.03027206 0.         0.014012  ]\n",
      "  [0.         0.         0.         ... 0.02697407 0.         0.01365763]\n",
      "  ...\n",
      "  [0.00668615 0.         0.         ... 0.01203967 0.         0.01342856]\n",
      "  [0.00726228 0.         0.         ... 0.01208384 0.         0.01328893]\n",
      "  [0.00706251 0.         0.         ... 0.01254906 0.         0.01360705]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.03404926 0.         0.01377736]\n",
      "  [0.         0.         0.         ... 0.02975895 0.         0.01331723]\n",
      "  [0.         0.         0.         ... 0.02648008 0.         0.01326891]\n",
      "  ...\n",
      "  [0.00434188 0.         0.         ... 0.01385447 0.         0.01637957]\n",
      "  [0.00417644 0.         0.         ... 0.01389732 0.         0.01662645]\n",
      "  [0.0042379  0.         0.         ... 0.01382516 0.         0.01674804]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.03392515 0.         0.01343767]\n",
      "  [0.         0.         0.         ... 0.02964832 0.         0.01273761]\n",
      "  [0.         0.         0.         ... 0.0263144  0.         0.01222662]\n",
      "  ...\n",
      "  [0.0061661  0.         0.         ... 0.01374343 0.         0.01346197]\n",
      "  [0.00621627 0.         0.         ... 0.01387638 0.         0.01363474]\n",
      "  [0.00664123 0.         0.         ... 0.01371254 0.         0.01354576]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.         ... 0.03435046 0.         0.01412143]\n",
      "  [0.         0.         0.         ... 0.03037049 0.         0.01402712]\n",
      "  [0.         0.         0.         ... 0.02721579 0.         0.01398655]\n",
      "  ...\n",
      "  [0.00751094 0.         0.         ... 0.01292888 0.         0.01396384]\n",
      "  [0.00671593 0.         0.         ... 0.013453   0.         0.01480964]\n",
      "  [0.00547444 0.         0.         ... 0.01420988 0.         0.01582027]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.03392515 0.         0.01343767]\n",
      "  [0.         0.         0.         ... 0.02927994 0.         0.01232391]\n",
      "  [0.00113393 0.         0.         ... 0.0256312  0.         0.01170867]\n",
      "  ...\n",
      "  [0.00403729 0.         0.         ... 0.01391034 0.         0.01667692]\n",
      "  [0.00438269 0.         0.         ... 0.01401519 0.         0.01664107]\n",
      "  [0.00534102 0.         0.         ... 0.01367245 0.         0.01605839]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.03443085 0.         0.01417797]\n",
      "  [0.         0.         0.         ... 0.03059013 0.         0.01416203]\n",
      "  [0.         0.         0.         ... 0.02720471 0.         0.01388796]\n",
      "  ...\n",
      "  [0.00363107 0.         0.         ... 0.01613309 0.         0.0144977 ]\n",
      "  [0.00418946 0.         0.         ... 0.01585258 0.         0.01425698]\n",
      "  [0.00446231 0.         0.         ... 0.01566616 0.         0.01428233]]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8a9e38509941>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_text\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mpredict_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_text\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;31m#train_accuracy = sum(1 for x, y in zip(y_text[:,1], predict_train[:,1]) if x==y) / len(y_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mpredict_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "acc_value = accuracy(y, y_text)\n",
    "with tf.device('/cpu:0'):\n",
    "    sess.run(init)\n",
    "    for epoch in range(NB_EPOCHS):\n",
    "        ptr = 0\n",
    "        for j in range(no_of_batches):\n",
    "            inp, out = X_text[ptr:ptr+BATCH_SIZE], y_text[ptr:ptr+BATCH_SIZE]\n",
    "            ptr += BATCH_SIZE\n",
    "            \n",
    "            s = sess.run(optimizer, feed_dict={x: X_text, y_: y_text})\n",
    "            predict_train = sess.run(y, feed_dict={x: X_text})\n",
    "            #train_accuracy = sum(1 for x, y in zip(y_text[:,1], predict_train[:,1]) if x==y) / len(y_text)\n",
    "            predict_val = []\n",
    "            val_accuracy = []\n",
    "        #with sess.as_default():\n",
    "            #print(acc_value.eval(predict_train, y_text))\n",
    "        \n",
    "       \n",
    "        if(j+1) % display_step ==0:\n",
    "            #c = sess.run(acc_value(feed_dict={y: predict_train, y_text: y_text}))\n",
    "            #c = sess.run(loss, feed_dict={x: X_text, y: y_text})\n",
    "            print(\"Epoch:\" '%04d' % (epoch+1),\n",
    "                 \"Cost:\", predict_train)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 700 \n",
    "LAYER_NUM = 2\n",
    "NB_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(HIDDEN_DIM,\n",
    "               input_shape=(None, VOCAB_SIZE),\n",
    "               return_sequences = True))\n",
    "\n",
    "for _ in range(LAYER_NUM - 1):\n",
    "    model.add(CuDNNLSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "#model.add(Activation('NULA'))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, length):\n",
    "  ix = [np.random.randint(VOCAB_SIZE)]\n",
    "  y_char = [idx_to_char[ix[-1]]]\n",
    "  X = np.zeros((1, length, VOCAB_SIZE))\n",
    "  for i in range(length):\n",
    "    X[0, i, :][ix[-1]] = 1.\n",
    "    ix = np.argmax(model.predict(X[:, :i+1,:])[0], 1)\n",
    "    y_char.append(idx_to_char[ix[-1]])\n",
    "  return ''.join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "# callback to save the model if better\n",
    "filepath=\"tgt_model.hdf5\"\n",
    "save_model_cb = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callback to stop the training if no improvement\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=0)\n",
    "# callback to generate text at epoch end\n",
    "class generateText(Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        print(generate_text(self.model, 100))\n",
    "        \n",
    "generate_text_cb = generateText()\n",
    "\n",
    "callbacks_list = [save_model_cb, early_stopping_cb, generate_text_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, epochs=NB_EPOCHS, callbacks=callbacks_list, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "filepath=\"tgt_model.hdf5\"\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
